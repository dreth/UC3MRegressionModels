---
title: 'Regression Models: Assignment 2'
author: "Daniel Alonso"
date: "January 11th, 2020"
output: 'pdf_document'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = '#>',
fig.path = './figures/'
)
```

## Installing libraries used

```{r, echo=TRUE, warning=FALSE, message=FALSE, results="hide", eval=FALSE}
packages = c("dplyr","MuMIn","MASS","leaps","glmnet","car","stringr","ResourceSelection"
             "boot","statmod","Epi", "Metrics", "caret", "ggplot2", "multcomp", "combinat")
for (package in packages) {
    install.packages(package)
}
```

## Importing libraries

```{r, echo=TRUE, warning=FALSE, message=FALSE, results="hide"}
library(dplyr)
library(MuMIn)
library(MASS)
library(leaps)
library(glmnet)
library(car)
library(stringr)
library(ResourceSelection)
library(boot)
library(statmod)
library(Epi)
library(Metrics)
library(caret)
library(ggplot2)
library(multcomp)
library(combinat)
```

\newpage

## Exercise 1

### Model and parameter interpretation

*Y* = Binary variable representing whether the customer will buy a car or not
*income* = annual family income

Therefore we model the response as:

$\eta = \beta_{0} + \beta_{1} X + \epsilon$

And our values will be:

$\eta = e^{-1.98079} + X e^{0.04342} + \epsilon$

Where $X$ is the annual family income.

The odds increase by $e^{\beta_{1}} = 1.044376$ if the predictor is increased by one unit.

```{r, echo=TRUE, warning=FALSE, message=FALSE}

```

### 95%-CI for the probability that a family with annual income of 60 thousand dollars will purchase a new car next year.

We calculate the asymptotic $(1 - \alpha)\%$ confidence interval:

$\hat{\beta_{j}} \pm z_{\frac{\alpha}{2}} S.E. (\hat{\beta_{j}})$

With our values we get:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# defining a p function for prob
p = function(eta) (exp(eta)/(exp(eta)+1))

# CI-Z
z_95 <- qnorm(0.975)

# CI calculation
p(-1.98079 + z_95*0.85720 + 0.04342*60 + z_95*0.02011)
p(-1.98079 - z_95*0.85720 + 0.04342*60 - z_95*0.02011)
```

$0.2506618 \leq p_{60k} \leq 0.9124486$


### Grouping into 6 levels of income, what test is used and what are the DF of the test statistic

The appropriate test for this would be the Hosmer-Lemeshow test with $G=6$ (corresponding to 6 groups).

The DF of the test statistic for a Hosmer-Lemeshow test is $DF=G-2$, therefore, $DF = 4$

## Exercise 2

### Importing and manipulating the dataset

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cols <- c("age","lwt","race","smoke")
birthwt <- MASS::birthwt %>% dplyr::select(c("low",cols))
```

For race we should use a dummy variable per race:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
birthwt$white <- ifelse(birthwt$race == 1, 1, 0)
birthwt$black <- ifelse(birthwt$race == 2, 1, 0)
birthwt$other <- ifelse(birthwt$race == 3, 1, 0)
cols <- c("age", "lwt", "smoke", "white", "black", "other")
birthwt <- birthwt %>% dplyr::select(c("low",cols))
```


### Model fitting and selection

```{r, echo=TRUE, warning=FALSE, message=FALSE}
FM <- glm(low ~ ., data=birthwt, family=binomial)
staic <- stepAIC(FM, list(upper=~age*lwt*smoke*white*black*other, lower= ~1))
```

Using stepAIC we can see all the combinations classified by AIC. The model with the lowest AIC is the model that uses *lwt*, *smoke* and *white* and drops the *age*, *black* and *other* variables.

We can see the interactions between the variable selected and age are not particularly significant and don't seem to affect the model enough to consider them, in fact, the AIC is improved when these are not present.

We can see that in general, dropping the *age* variable yields a better result:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
staic$anova
```

```{r, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}
options(na.action=na.fail)
MuMIn::dredge(FM)
```

Using dredge also tells us the same as stepAIC, where the best model is the one at the top (as they are ranked by AIC already).

```{r, echo=TRUE, warning=FALSE, message=FALSE}
anova(FM, staic, test="Chisq")$"Pr(>Chi)"[2]
```

Performing a likelihood ratio test yields a good, high p-val of 0.668 so we pick the reduced model.

### Hosmer-Lemeshow test

```{r, echo=TRUE, warning=FALSE, message=FALSE}
hoslem.test(birthwt$low, predict(staic, type="response"))
```

We have a large p-value of 0.335 which indicates that our goodness of fit is most likely okay.

\newpage

### Residual plots and model assumptions

```{r, echo=TRUE, warning=FALSE, message=FALSE}
glm.diag.plots(staic)
```

As we have 2 sets of points for the Residuals vs Linear predictor and the Quantiles of standard normal vs Ordered deviance residuals, we can't properly interpret these.

For the cook's distance we can see there is a few slightly high leverage points . However, it is not significant as other than this there's no points present in the top right quadrant of the plot. 

\newpage

```{r, echo=TRUE, warning=FALSE, message=FALSE, fig.width=10, fig.height=7}
par(mfrow=c(2,1))
plot(birthwt$lwt, qres.binom(staic), xlab="lwt", ylab="Quantile residuals")
qqnorm(qres.binom(staic))
```

We decide not to plot the *race* or *smoke* variables given that, even though they're in the model, they're categorical variables.

For our *lwt* residual plot, everything seems to be okay, we see that. In the normal QQ plot we see that the values decently fit a normal distribution. This fits the normality assumption.

Our only continuous variable in the model (*lwt*) seems to have constant variance, therefore our model is homocedastic.

\newpage

### Total error rate of the model

```{r, echo=TRUE, warning=FALSE, message=FALSE}
Epi::ROC(form=low~lwt+white+smoke , data=birthwt, plot="ROC", lw=3, cex=1.5)
```

The model has an AUC = 0.684 which corresponds to a decent but not particularly good model, however, using this measure we can assert that the model does have predictive capability.

We can see our cutoff point is also 0.253.

Our model has a very high sensitivity, however, a very low specificity, therefore it also has a very high false negative rate. We could comfortably assert that this is the achilles heel of our model, as it still has a high accuracy for positives but a very low accuracy for negatives.

It would also be appropriate to look at the MAE and MSE for our model.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
Metrics::mae(birthwt$low, predict(staic, type="response"))
Metrics::mse(birthwt$low, predict(staic, type="response"))
```

We can see that they're both relatively low even though our model doesn't perform amazingly.

### Mothers having babies with low birth weight vs normal birth weight

First we will look at variable importance:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
caret::varImp(staic)
```

We can see that the most important variable of the model is the *smoke* variable, followed by *white* and then *lwt*.

We select a subset of the original dataset which uses the model prediction and we also select a subset of the original dataset using the real classification. Both for normal birth weight babies and low birth weight babies, in order to assess which elements are characteristic of each group.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# model's prediction
pred <- predict(staic, type="response")
normal_birth_weight <- birthwt[pred<0.253,]
low_birth_weight <- birthwt[pred>0.253,]

# reality
real_lbw <- birthwt %>% dplyr::filter(low == 1)
real_nbw <- birthwt %>% dplyr::filter(low == 0)
```

#### Smoke prevalence

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(normal_birth_weight$smoke)
```

We can see that as the model considers the variable smoke particularly important for prediction, it seems to very strongly influence its prediction of normal birth weight, therefore very effectively predicting those with normal birth weight. And as we clearly know, smoking is a high risk factor for birth issues like this. However, we can also notice that non-smokers tend to give birth to normal weight babies.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(low_birth_weight$smoke)
```

However, when comparing its prediction of low birth weight it falls short, as not all low birth weight babies come from a mother that smokes. The model fails about 60% of the time.

In contrast to the reality:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(real_lbw$smoke)
```

For low weight babies there's about a 50% chance that the mother is a smoker

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(real_nbw$smoke)
```

While it is significantly more probable that the mother is not a smoker when the baby has a normal birth weight. We see that the amount of non-smoker mothers represent about 66% of the normal birth weight subset.

\newpage

#### Age

```{r, echo=FALSE, warning=FALSE, message=FALSE}
print(stringr::str_interp('low birth weight: ${mean(low_birth_weight$age)}'))
print(stringr::str_interp('normal birth weight: ${mean(normal_birth_weight$age)}'))
```

We can see that according to the model, the median age of mothers giving birth to normal weight babies is ~25.15 years old, while the ones with low birth weight babies are ~22.35 years old.

In contrast to the reality though:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
print(stringr::str_interp('low birth weight: ${mean(real_lbw$age)}'))
print(stringr::str_interp('normal birth weight: ${mean(real_nbw$age)}'))
```

There doesn't seem to be a significant age difference (~1 year).

#### Mother's weight

```{r, echo=TRUE, warning=FALSE, message=FALSE}
print(stringr::str_interp('low birth weight: ${mean(low_birth_weight$lwt)}'))
print(stringr::str_interp('normal birth weight: ${mean(normal_birth_weight$lwt)}'))
```

The mother's weight shows significant difference for the prediction, where normal birth weight mom's weight (on average) about 34 pounds more.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
print(stringr::str_interp('low birth weight: ${mean(real_lbw$lwt)}'))
print(stringr::str_interp('normal birth weight: ${mean(real_nbw$lwt)}'))
```

However, in reality, the difference is ~11 pounds on average for our dataset.

#### Mother's race (binary if white)

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(low_birth_weight$white)
```

The model is significantly biased towards the white race group where most low birth weight babies come from non-white mothers (about 2x more likely).

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(normal_birth_weight$white)
```

We also see that race group 1 has the highest representation among those mothers with normal birth weight babies.

In contrast to the reality:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(real_lbw$white)
```

We can see that in the real dataset, race doesn't quite seem to play the role that the model portrays it to have in whether a baby has low birth weight or not.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
table(real_lbw$white)
table(real_nbw$white)
```

There's a clear overrepresentation of race group 1 in the normal birth weight subset.

#### What characteristic had the highest impact?

Following the model's result, we can definitely say that whether the mother was a smoker or not had the highest influence in its prediction, followed by the race, where there was a huge overrepresentation of group 3 in the low birth weight group.

## Exercise 3

```{r, echo=TRUE, warning=FALSE, message=FALSE}
health <- read.table('../data/health.txt', header=TRUE)
cols <- c("g02","sex","weight")
health <- health %>% dplyr::select(g02,sex,weight)
```

```{r, echo=TRUE, warning=FALSE, message=FALSE}
mean(health[health$sex==1,]$weight)
mean(health[health$sex==2,]$weight)
```

We will make the assumption that for the *sex* column *1 = males* and *2 = females*, as average weight for males is (generally) higher for pretty much every country.

We will subtract 1 from the *sex* column to make it a binary variable with only 1s and 0s.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
health$sex <- health$sex - 1
```

```{r, echo=TRUE, warning=FALSE, message=FALSE}
fm <- glm(g02 ~ sex+weight+sex:weight, data=health, family=binomial)
model <- glm(g02 ~ sex+weight, data=health, family=binomial)
anova(fm, model, test="Chisq")
```

The interaction between sex and weight is significant, therefore we will include it in the model.

\newpage

### Interpreting the coefficients in terms of the OR

$\eta = log(\frac{p}{1-p})$

$\eta = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k$ 

In terms of the odds:

$Odds = e^{2.56152 + 1.236831 X_1 - 0.01171 X_2 - 0.028984 X_1 X_2}$

Where $X_1$ represents *sex*, $X_2$ represents *weight* and $X_1 X_2$ represents *sex:weight*.

For the odds ratio, we should highlight the differences between males and females.

Therefore:

$O_R = \frac{e^{2.56152 - 0.01171 X_2}}{e^{2.56152 + 1.236831 X_1 - 0.01171 X_2 - 0.028984 X_1 X_2}}$

Where the numerator of the fraction corresponds to the odds for **males** and the denominator corresponds to the odds for **females**.

### Plotting predicted probabilities for males and females

```{r, echo=TRUE, warning=FALSE, message=FALSE}
health$pred_prob <- predict(fm, type='response')
Sex <- ifelse(health$sex == 1, "female", "male")
ggplot(data=health, aes(color=Sex)) + geom_point(aes(x=weight, y=pred_prob))
```

We can see a trend here, men are significantly more likely to consider themselves healthy. The model is also telling us that weight negatively affects the probability to feel healthy in a significant way, however, much more significantly on females than males. 

Both men and women seem to consider weight an important factor in their health perception. The lower usually tends to mean the better, however, it's clear that being underweight isn't a healthy trait, but some people might think otherwise.

\newpage

### Relative risk and odds ratio of self-perceived good health per sex for a 75kg person

We predict for both males and females by specifying the *sex=0* (for males) and *sex=1* (for females) and *weight=75* for both sexes.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
males <- predict(fm, newdata=data.frame(sex=0,weight=75), type="response")
females <- predict(fm, newdata=data.frame(sex=1,weight=75), type="response")
```

We calculate the relative risk:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
females/males
```

And the odds Ratio:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
(females/(1-females))/(males/(1-males))
```

We can say that females are *0.3918128* times less likely to have self-perceived good health than males.

### Estimated expected probability of self-perceived good health of females of 70kg and 110kg with CI

#### Females of 70kg

```{r, echo=TRUE, warning=FALSE, message=FALSE}
predict(fm, newdata=data.frame(sex=1,weight=70), type="response")
```

The expected probability of self-perceived good health for 70kg females is of ~0.721.

#### Females of 110kg

```{r, echo=TRUE, warning=FALSE, message=FALSE}
predict(fm, newdata=data.frame(sex=1,weight=110), type="response")
```

The expected probability of self-perceived good health for 110kg females is of ~0.336.

#### 95%-CI for the prob. of self-perceived good health for a 70kg female

```{r, echo=TRUE, warning=FALSE, message=FALSE}
w1 <- predict(fm, newdata=data.frame(sex=1,weight=70), type="link", se.fit=TRUE)

p(w1$fit - qnorm(0.975)*w1$se.fit)
p(w1$fit + qnorm(0.975)*w1$se.fit)
```

The confidence interval for the probability of self-perceived good health for a 70kg female is:

$0.7015783 \leq \beta_{70kg} \leq 0.7396794$

\newpage

#### 95%-CI for the prob. of self-perceived good health for a 110kg female

```{r, echo=TRUE, warning=FALSE, message=FALSE}
w2 <- predict(fm, newdata=data.frame(sex=1,weight=110), type="link", se.fit=TRUE)

p(w2$fit - qnorm(0.975)*w2$se.fit)
p(w2$fit + qnorm(0.975)*w2$se.fit)
```

 
The confidence interval for the probability of self-perceived good health for a 70kg female is:

$0.2609291 \leq \beta_{110kg} \leq 0.4217766$

## Exercise 4

Importing and manipulating the data:

We exclude  *g01* as it seems to interfere with the predictions (probably because the target variable *g02* seems to be based on *g01*). 

Also, during testing, year didnt seem to influence the model very much.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
health <- read.table('../data/health.txt', header=TRUE)
cols <- names(health)[names(health) != "g01"]
health <- health %>% dplyr::select(cols)

# taking one from sex to have it as 0, 1
health$sex <- health$sex - 1
```

We create a model which includes all the variables and their interactions:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
fm <- glm(g02~sex*weight*height*con_tab*educa*drink*age*year*imc, data=health, family=binomial)
```

The approach of this algorithm is at follows:

1 - We create a vector with the column names excluding g02

2- 

```{r, echo=TRUE, warning=FALSE, message=FALSE, eval=FALSE}
# exclude target
cols <- names(health)[names(health) != "g02"]
vars <- list()
best_models <- list()
everything <- list()
for (i in 2:7) {
    best_models[[i]] <- combinat::combn(cols,i)
    aics_l <- c()
    bics_l <- c()
    lrts_l <- c()
    for (k in 1:(length(best_models[[i]])/i)) {
        mods <- paste(best_models[[i]][,k],collapse="+")
        curr_model <- stringr::str_interp('g02~(${mods})^2')
        md <- glm(curr_model, data=health, family=binomial)
        aic_optimized <- stepAIC(md)
        aics_l <- c(aics_l, AIC(aic_optimized))
        bics_l <- c(bics_l, BIC(aic_optimized))
        test <- anova(fm, aic_optimized, test="Chisq")
        lrts_l <- c(lrts_l, test$"Pr(>Chi)"[2])
    }
    mod <- 1:length(best_models[[i]])
    everything[[i]] <- data.frame(mod=mod,aics=aics_l,bics=bics_l,lrts=lrts_l)
}
```

We use stepAIC to obtain the best model based on AIC and stepAIC with the parameter $k=log(n)$ to obtain the best model based on BIC.


```{r, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}
# using stepAIC
staic <- stepAIC(mod)
```

After 

```{r, echo=TRUE, warning=FALSE, message=FALSE}
# using stepBIC
n = dim(health)[1]
stepAIC(mod, k=log(n))
```

## Exercise 5

Importing and manipulating the data:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
crime <- read.table('../data/Campus_Crime.txt', header=TRUE)
crime$Type <- as.factor(crime$Type)
crime$Region <- as.factor(crime$Region)
```

We first create both a model (using the variables *Region* and *Type*) with and without the interactions:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
fm <- glm(Property~Region+Type+Region:Type, data=crime, family=poisson, offset=log(Enrollment))
model <- glm(Property~Region+Type, data=crime, family=poisson, offset=log(Enrollment))
```

We test for the significance of the interactions between the different variables:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
anova(fm, model, test="Chisq")
```

Given their p-val in the LRT, we can assert that the interactions are significant and we cannot drop them, basically, incidence of property crime has a significant relationship to whether it occurs in C (College) or U (University).

Our reference region is a College in the Central region, corresponding to the following model:

$\lambda_0 = e^{-4.9006}$

In contrast, this is how the model would look like if we select a University in the southwest region:

$\lambda_1 = \frac{e^{0.3155}}{e^{0.1854} e^{0.6978} e^{4.9006}}$

However, we still have to optimize the model, to achieve this, we will use *stepAIC* in order to find the model with the best AIC. 

```{r, echo=TRUE, warning=FALSE, message=FALSE}
stepAIC(model, list(upper=~Region*Type, lower= ~1))
```

We see that according to stepAIC, the best model is the one that includes all the interactions between the variables. Returning a model with an AIC of 4300.

## Exercise 6

